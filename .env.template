# ============================================
# AZURE OPENAI CONNECTION SETTINGS (REQUIRED)
# ============================================

# Your Azure OpenAI endpoint
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Your Azure OpenAI API key
AZURE_OPENAI_KEY=your-api-key-here

# API version (usually don't need to change)
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Your GPT deployment name
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Your embedding deployment name
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002


# ============================================
# PROCESSING SETTINGS (OPTIONAL)
# ============================================

# Number of conversations per batch
BATCH_SIZE=100

# Number of parallel workers
MAX_WORKERS=10

# Retry configuration
MAX_RETRIES=3
RETRY_DELAY=2

# Token limit per request
MAX_TOKENS_PER_REQUEST=4000


# ============================================
# TAXONOMY SETTINGS (OPTIONAL)
# ============================================

# Similarity thresholds
SIMILARITY_THRESHOLD=0.88
TOPIC_SIMILARITY_THRESHOLD=0.90
MIN_CONFIDENCE_NEW_CATEGORY=0.85

# Auto-save interval (seconds)
AUTO_SAVE_INTERVAL=60


# ============================================
# QUALITY SETTINGS (OPTIONAL)
# ============================================

MIN_CONVERSATION_LENGTH=2
MAX_CONVERSATION_LENGTH=100
QUALITY_SCORE_THRESHOLD=0.7
ENABLE_DETAILED_LOGS=true

You are acting as a senior ML / Applied AI engineer.

Context:
We process ~70,000 customer support conversations per day.
Each conversation is summarized using an LLM into structured fields such as:
- Customer problem
- Bot action
- Outcome
- High-level category
- Sentiment

The summaries are already generated using OpenAI with a strict response schema.
Each conversation currently uses ~2 LLM calls (~500 tokens per call).

Objective:
We want to deploy this system to production and need a practical, industry-standard
approach for guardrails, hallucination control, and evaluation metrics that scales
to high volume without evaluating 100% of traffic.

Constraints:
- We cannot run additional LLM evaluations on every conversation due to cost.
- Evaluation must be asynchronous and non-blocking.
- Total evaluation cost should remain under ~5â€“10% of generation cost.
- The solution must be production-ready and defensible in design reviews.

What we are looking for:
1. Guardrails to apply on 100% of traffic (schema, grounding, sanity checks).
2. A scalable evaluation strategy (sampling-based, risk-weighted if needed).
3. Metrics to track hallucinations, field accuracy, and overall quality.
4. How to measure hallucinations in practice (LLM-as-judge, human gold sets, etc.).
5. Monitoring and alerting approach for drift and quality regressions.
6. Clear thresholds that would trigger alerts or rollback.
7. Optional: architecture or pipeline suggestions.

Please propose:
- The evaluation framework
- The key metrics and how to compute them
- Sampling strategy and frequencies
- Any best practices commonly used in production LLM systems at scale
